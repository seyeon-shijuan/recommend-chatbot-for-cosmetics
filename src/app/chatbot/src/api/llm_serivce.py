class LLMService():
    
    def inference(self, prompt):
        return {
            "answer": "test answer"
        }