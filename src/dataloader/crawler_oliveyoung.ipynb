# 페이지별 상품 리뷰 크롤링 함수
def review_crawling(df, page_num):
    for current_page in range(1, page_num + 1):
        # 리뷰의 인덱스는 한 페이지 내에서 1~10까지 존재
        for i in range(1, 11):  # 한 페이지 내 10개 리뷰 크롤링
            try:
                id = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}]) > div.info > div > p.info_user > a.id').text
                category = '스킨/토너'
                brand_string = driver.find_element(By.CSS_SELECTOR, f'#Contents > div.prd_detail_box.renew > div.right_area > div > p.prd_name').text  
                brand_ = re.search(r'\] (.+?) \(', brand_string)
                if brand:
                    brand = brand.group(1)
                    print(brand)
                else:
                    print("매칭되는 부분이 없습니다.")                
                rate = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.score_area > span.review_point > span').text
                skin_type = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.poll_sample > dl:nth-child(1) > dd > span').text
                select_1_title = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.poll_sample > dl:nth-child(1) > dt > span').text
                select_1_content = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.poll_sample > dl:nth-child(1) > dd > span').text
                select_2_title = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.poll_sample > dl:nth-child(2) > dt > span').text
                select_2_content = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.poll_sample > dl:nth-child(2) > dd > span').text
                select_3_title = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.poll_sample > dl:nth-child(3) > dt > span').text
                select_3_content = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.poll_sample > dl:nth-child(3) > dd > span').text
                txt = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({i}) > div.review_cont > div.txt_inner').text
                df.loc[len(df)] = [id, 'category', 'brand', rate, skin_type, select_1_title, select_1_content, select_2_title, select_2_content, select_3_title, select_3_content, txt]
            except Exception as e:
                print(f"에러 발생: {str(e)}")

        try:
            if current_page % 10 != 0:  # 현재 페이지가 10의 배수가 아닐 때
                if current_page // 10 < 1:  # 페이지 수가 한 자리수 일 때
                    # 리뷰 10개 긁으면 next 버튼 클릭
                    page_button = driver.find_element(By.CSS_SELECTOR, f'#gdasContentsArea > div > div.pageing > a:nth-child({current_page % 10 + 1})')
                    page_button.click()
                    time.sleep(2)
                else:  # 페이지 수가 두자리 수 이상일 때
                    # 리뷰 10개 긁으면 next 버튼 클릭
                    page_button = driver.find_element(By.CSS_SELECTOR, f'#gdasContentsArea > div > div.pageing > a:nth-child({current_page % 10 + 2})')
                    page_button.click()
                    time.sleep(2)
            else:
                next_button = driver.find_element(By.CSS_SELECTOR, '#gdasContentsArea > div > div.pageing > a.next')
                next_button.click()  # 현재 페이지가 10의 배수일 때 페이지 넘김 버튼 클릭
                time.sleep(2)
        except Exception as e:
            print(f"에러 발생: {str(e)}")

        print(f'{current_page}페이지 크롤링 완료')



# 웹 드라이버 설정
driver = webdriver.Chrome()

# 스킨/케어 페이지로 이동
driver.get('https://www.oliveyoung.co.kr/store/display/getCategoryShop.do?dispCatNo=10000010001&gateCd=Drawer&t_page=%EB%93%9C%EB%A1%9C%EC%9A%B0_%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_click=%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC%ED%83%AD_%EB%8C%80%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC&t_1st_category_type=%EB%8C%80_%EC%8A%A4%ED%82%A8%EC%BC%80%EC%96%B4')

# 데이터 셋 생성
df_review_cos1 = pd.DataFrame(columns=['id', 'category','brand', 'rate', 'skin_type', 'select_1_title', 'select_1_content', 'select_2_title', 'select_2_content', 'select_3_title', 'select_3_content', 'txt'])

# 스킨/토너 버튼 클릭
skin_toner_button = driver.find_element(By.XPATH, '//*[@id="Contents"]/div/div[1]/ul/li[1]/a')
skin_toner_button.click()
time.sleep(2)

# 페이지 번호 초기화
page_number = 1

while page_number <= 15: # 페이지 끝 임의로 설정
    # 현재 페이지의 모든 화장품 이미지 버튼을 클릭
    for row in range(1, 7):
        for col in range(1, 5):
            image_button_xpath = f'//*[@id="Contents"]/ul[{row + 1}]/li[{col}]/div/a'
            image_button = driver.find_element(By.XPATH, image_button_xpath)
            image_button.click()
            time.sleep(2)
            
            # 리뷰 버튼 클릭
            review_button = driver.find_element(By.XPATH, '//*[@id="reviewInfo"]/a')
            review_button.click()

            # 리뷰 및 정보 수집 
            review_data = review_crawling(driver.page_source, page_number)

            # 데이터프레임에 데이터 추가
            df_review_cos1 = df_review_cos1.append(review_data, ignore_index=True)


            # 이미지 목록이 있는 페이지로 돌아가기
            driver.back()
    
    # 페이지 이동 후 로딩을 기다리기 위한 시간 지연
    time.sleep(2)

    # 10 페이지가 되면 화살표 버튼을 클릭하여 다음 페이지로 이동
    if page_number % 10 == 0:
        arrow_button_xpath = '//*[@id="Container"]/div[2]/a[10]'
        driver.find_element(By.XPATH, arrow_button_xpath).click()
        time.sleep(2)
    else:
        # 10 페이지가 아니면 a 태그 클릭
        a_index = (page_number - 1) % 10 + 1
        a_element_xpath = f'//*[@id="Container"]/div[2]/a[{a_index}]'
        driver.find_element(By.XPATH, a_element_xpath).click()

    # 페이지 번호 증가
    page_number += 1
    

# CSV 파일로 저장
df_review_cos1.to_csv('review_cos1_data.csv', index=False)

# 웹 드라이버 종료
driver.quit()
